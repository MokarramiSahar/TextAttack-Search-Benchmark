{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import notebook as tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import torch\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PYTORCH_DEVICE = 0\n",
    "TF_DEVICE = 1\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Metric:\n",
    "    def __init__(self):\n",
    "        self._model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "        self._model.to(device=f'cuda:{PYTORCH_DEVICE}')\n",
    "        self._tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", use_fast=True)\n",
    "        \n",
    "    def perplexity(self, text):\n",
    "        input_ids = self._tokenizer.encode(text)\n",
    "        input_ids = input_ids[: self._tokenizer.model_max_length - 2]\n",
    "        input_ids.insert(0, self._tokenizer.bos_token_id)\n",
    "        input_ids.append(self._tokenizer.eos_token_id)\n",
    "        input_ids = torch.tensor(input_ids)\n",
    "        input_ids = input_ids.to(device=f'cuda:{PYTORCH_DEVICE}')\n",
    "        with torch.no_grad():\n",
    "            loss = self._model(input_ids, labels=input_ids)[0].item()\n",
    "    \n",
    "        perplexity = math.exp(loss)\n",
    "        return perplexity\n",
    "    \n",
    "    def calc_metric(self, orig_text, new_text):\n",
    "        orig_perplexity = self.perplexity(orig_text)\n",
    "        new_perplexity = self.perplexity(new_text)\n",
    "        return (new_perplexity - orig_perplexity) / orig_perplexity\n",
    "    \n",
    "\n",
    "class USEMetric:\n",
    "    def __init__(self):\n",
    "        tfhub_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "        with tf.device(f'/device:GPU:{TF_DEVICE}'):\n",
    "            self._model = hub.load(tfhub_url)\n",
    "\n",
    "    def encode(self, orig_text, new_text):\n",
    "        with tf.device(f'/device:GPU:{TF_DEVICE}'):\n",
    "            return self._model([orig_text, new_text]).numpy()\n",
    "    \n",
    "    def get_angular_sim(self, emb1, emb2):\n",
    "        cos_sim = torch.nn.CosineSimilarity(dim=0)(emb1, emb2)\n",
    "        return 1 - (torch.acos(cos_sim) / math.pi)\n",
    "    \n",
    "    def calc_metric(self, orig_text, new_text):\n",
    "        orig_emb, new_emb = self.encode(orig_text, new_text)\n",
    "        orig_emb = torch.tensor(orig_emb)\n",
    "        new_emb = torch.tensor(new_emb)\n",
    "        sim = self.get_angular_sim(orig_emb, new_emb).item()\n",
    "        return sim\n",
    "\n",
    "class PercentageOfWordsChanged:\n",
    "    def calc_metric(self, orig_text, new_text):\n",
    "        orig_words = np.array(orig_text.split())\n",
    "        new_words = np.array(new_text.split())\n",
    "        words_changed = (orig_words != new_words).sum()\n",
    "        return words_changed * 100 / len(orig_words)\n",
    "    \n",
    "class Evaluator:\n",
    "    def __init__(self):\n",
    "        self.use_metric = USEMetric()\n",
    "        self.gpt2_metric = GPT2Metric()\n",
    "        self.percentageOfWordsChanged = PercentageOfWordsChanged()\n",
    "        \n",
    "    def evaluate(self, csv_file, all_successful):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df = df[df['result_type']==\"Successful\"]\n",
    "\n",
    "        total_sim = 0\n",
    "        total_pp_diff = 0\n",
    "        word_changed_percent = 0\n",
    "        N = 0\n",
    "        for i, row in df.iterrows():\n",
    "            original_text = row[\"original_text\"].replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "            if original_text not in all_successful:\n",
    "                continue\n",
    "            perturbed_text = row[\"perturbed_text\"].replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "            sim = self.use_metric.calc_metric(original_text, perturbed_text)\n",
    "            total_sim += sim\n",
    "            pp_diff = self.gpt2_metric.calc_metric(original_text, perturbed_text)\n",
    "            total_pp_diff += pp_diff\n",
    "            word_changed_percent += self.percentageOfWordsChanged.calc_metric(original_text, perturbed_text)\n",
    "            N += 1\n",
    "\n",
    "        return total_sim / N, total_pp_diff / N, word_changed_percent / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/4'.\n",
      "INFO:absl:Downloaded https://tfhub.dev/google/universal-sentence-encoder/4, Total size: 987.47MB\n",
      "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/4'.\n",
      "WARNING:transformers.modeling_utils:Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models = [\"bert-yelp-test\"]\n",
    "models = [\"lstm-yelp-test\", \"lstm-mr-test\"]\n",
    "model_dataset_names = {\n",
    "    \"bert-mr-test\": \"BERT Movie Reviews\",\n",
    "    \"bert-yelp-test\": \"BERT Yelp Polarity\",\n",
    "    \"bert-snli-test\": \"BERT SNLI\",\n",
    "    \"lstm-mr-test\": \"LSTM Movie Reviews\",\n",
    "    \"lstm-yelp-test\": \"LSTM Yelp Polarity\",\n",
    "}\n",
    "transformations = [\"word-swap-embedding\", \"word-swap-hownet\", \"word-swap-wordnet\"]\n",
    "constraint_levels = [\"strict\"]\n",
    "search_methods = [\"greedy\", \"beam4\", \"beam8\", \"greedyWIR_unk\", \"greedyWIR_delete\", \"greedyWIR_pwws\", \"greedyWIR_random\", \"genetic\", \"pso\"]\n",
    "#search_methods=[\"pso\"]\n",
    "search_method_names = {\n",
    "    'greedy': 'Greedy [b=1]',\n",
    "    'beam4': 'Beam Search [b=4]',\n",
    "    'beam8': 'Beam Search [b=8]',\n",
    "    'greedyWIR_unk': 'Greedy WIR [UNK]',\n",
    "    'greedyWIR_delete': 'Greedy WIR [DEL]',\n",
    "    'greedyWIR_random': 'Greedy WIR [RAND]',\n",
    "    'greedyWIR_pwws': 'Greedy WIR [PWWS]',\n",
    "    'genetic': 'Genetic Algorithm',\n",
    "    'pso': 'Particle Swarm Optimization'\n",
    "}\n",
    "RESULT_ROOT_DIR = \"./results\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6499274c66e4b73ad63ef4d8277cd4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=54.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_successful_attacks = []\n",
    "num_files = len(models) * len(transformations) * len(constraint_levels) * len(search_methods)\n",
    "pbar = tqdm.tqdm(total=num_files, smoothing=0)\n",
    "for model in models:\n",
    "    for t in transformations:\n",
    "        for cl in constraint_levels:\n",
    "            all_successful = set()\n",
    "            for sm in search_methods:\n",
    "                csv_path = f\"{RESULT_ROOT_DIR}/{model}/{t}/{cl}/{sm}.csv\"\n",
    "                df = pd.read_csv(csv_path)\n",
    "                df = df[df['result_type']==\"Successful\"]\n",
    "                df[\"original_text\"] = df.apply(lambda row: row[\"original_text\"].replace(\"[\",\"\").replace(\"]\",\"\"), axis=1)\n",
    "                if len(all_successful) == 0:\n",
    "                    all_successful = set(df[\"original_text\"])\n",
    "                else:\n",
    "                    all_successful = all_successful.intersection(set(df[\"original_text\"]))\n",
    "                pbar.update(1)\n",
    "            all_successful_attacks.append(all_successful)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13939c09db2d42eb81c48f64a3baa51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=54.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "lstm-yelp-test/word-swap-embedding/strict\n",
      "---------------------------------------------\n",
      "greedy: word_changed_percent=4.09, sim=0.942, pp_diff=29.6%\n",
      "beam4: word_changed_percent=4.06, sim=0.942, pp_diff=29.6%\n",
      "beam8: word_changed_percent=4.06, sim=0.942, pp_diff=29.4%\n",
      "greedyWIR_unk: word_changed_percent=5.95, sim=0.932, pp_diff=44.0%\n",
      "greedyWIR_delete: word_changed_percent=5.93, sim=0.932, pp_diff=42.3%\n",
      "greedyWIR_pwws: word_changed_percent=4.66, sim=0.939, pp_diff=34.0%\n",
      "greedyWIR_random: word_changed_percent=7.34, sim=0.924, pp_diff=54.7%\n",
      "genetic: word_changed_percent=6.01, sim=0.932, pp_diff=44.0%\n",
      "pso: word_changed_percent=6.75, sim=0.928, pp_diff=48.4%\n",
      "=============================================\n",
      "=============================================\n",
      "lstm-yelp-test/word-swap-hownet/strict\n",
      "---------------------------------------------\n",
      "greedy: word_changed_percent=2.5, sim=0.948, pp_diff=23.9%\n",
      "beam4: word_changed_percent=2.5, sim=0.948, pp_diff=23.7%\n",
      "beam8: word_changed_percent=2.48, sim=0.949, pp_diff=23.0%\n",
      "greedyWIR_unk: word_changed_percent=3.58, sim=0.934, pp_diff=34.9%\n",
      "greedyWIR_delete: word_changed_percent=3.66, sim=0.935, pp_diff=33.7%\n",
      "greedyWIR_pwws: word_changed_percent=2.63, sim=0.946, pp_diff=24.3%\n",
      "greedyWIR_random: word_changed_percent=6.42, sim=0.905, pp_diff=70.0%\n",
      "genetic: word_changed_percent=3.81, sim=0.929, pp_diff=42.3%\n",
      "pso: word_changed_percent=5.07, sim=0.924, pp_diff=58.7%\n",
      "=============================================\n",
      "=============================================\n",
      "lstm-yelp-test/word-swap-wordnet/strict\n",
      "---------------------------------------------\n",
      "greedy: word_changed_percent=4.62, sim=0.946, pp_diff=52.3%\n",
      "beam4: word_changed_percent=4.57, sim=0.946, pp_diff=52.1%\n",
      "beam8: word_changed_percent=4.54, sim=0.946, pp_diff=51.5%\n",
      "greedyWIR_unk: word_changed_percent=7.27, sim=0.935, pp_diff=75.8%\n",
      "greedyWIR_delete: word_changed_percent=7.28, sim=0.935, pp_diff=75.7%\n",
      "greedyWIR_pwws: word_changed_percent=5.19, sim=0.944, pp_diff=57.3%\n",
      "greedyWIR_random: word_changed_percent=9.44, sim=0.924, pp_diff=102.8%\n",
      "genetic: word_changed_percent=6.41, sim=0.936, pp_diff=81.3%\n",
      "pso: word_changed_percent=8.02, sim=0.93, pp_diff=95.4%\n",
      "=============================================\n",
      "=============================================\n",
      "lstm-mr-test/word-swap-embedding/strict\n",
      "---------------------------------------------\n",
      "greedy: word_changed_percent=7.16, sim=0.899, pp_diff=33.2%\n",
      "beam4: word_changed_percent=7.16, sim=0.899, pp_diff=33.3%\n",
      "beam8: word_changed_percent=7.16, sim=0.899, pp_diff=33.6%\n",
      "greedyWIR_unk: word_changed_percent=8.93, sim=0.889, pp_diff=41.3%\n",
      "greedyWIR_delete: word_changed_percent=9.15, sim=0.889, pp_diff=44.6%\n",
      "greedyWIR_pwws: word_changed_percent=7.42, sim=0.898, pp_diff=33.4%\n",
      "greedyWIR_random: word_changed_percent=10.52, sim=0.88, pp_diff=53.3%\n",
      "genetic: word_changed_percent=8.0, sim=0.895, pp_diff=36.1%\n",
      "pso: word_changed_percent=8.36, sim=0.893, pp_diff=39.9%\n",
      "=============================================\n",
      "=============================================\n",
      "lstm-mr-test/word-swap-hownet/strict\n",
      "---------------------------------------------\n",
      "greedy: word_changed_percent=6.08, sim=0.883, pp_diff=38.8%\n",
      "beam4: word_changed_percent=6.08, sim=0.883, pp_diff=38.8%\n",
      "beam8: word_changed_percent=6.08, sim=0.883, pp_diff=38.8%\n",
      "greedyWIR_unk: word_changed_percent=7.43, sim=0.872, pp_diff=44.7%\n",
      "greedyWIR_delete: word_changed_percent=7.44, sim=0.872, pp_diff=43.5%\n",
      "greedyWIR_pwws: word_changed_percent=6.13, sim=0.883, pp_diff=38.9%\n",
      "greedyWIR_random: word_changed_percent=9.45, sim=0.853, pp_diff=58.7%\n",
      "genetic: word_changed_percent=6.54, sim=0.879, pp_diff=41.5%\n",
      "pso: word_changed_percent=6.49, sim=0.88, pp_diff=42.3%\n",
      "=============================================\n",
      "=============================================\n",
      "lstm-mr-test/word-swap-wordnet/strict\n",
      "---------------------------------------------\n",
      "greedy: word_changed_percent=10.24, sim=0.87, pp_diff=100.7%\n",
      "beam4: word_changed_percent=10.06, sim=0.871, pp_diff=98.9%\n",
      "beam8: word_changed_percent=10.03, sim=0.871, pp_diff=97.6%\n",
      "greedyWIR_unk: word_changed_percent=13.04, sim=0.856, pp_diff=104.8%\n",
      "greedyWIR_delete: word_changed_percent=13.07, sim=0.856, pp_diff=107.8%\n",
      "greedyWIR_pwws: word_changed_percent=10.54, sim=0.871, pp_diff=88.5%\n",
      "greedyWIR_random: word_changed_percent=16.07, sim=0.841, pp_diff=149.1%\n",
      "genetic: word_changed_percent=12.0, sim=0.859, pp_diff=120.3%\n",
      "pso: word_changed_percent=13.94, sim=0.853, pp_diff=131.2%\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "num_files = len(models) * len(transformations) * len(constraint_levels) * len(search_methods)\n",
    "pbar = tqdm.tqdm(total=num_files, smoothing=0)\n",
    "i = 0\n",
    "for model in models:\n",
    "    for t in transformations:\n",
    "        for cl in constraint_levels:\n",
    "            print(\"=\"*45)\n",
    "            print(f\"{model}/{t}/{cl}\")\n",
    "            print(\"-\"*45)\n",
    "            for sm in search_methods:\n",
    "                csv_path = f\"{RESULT_ROOT_DIR}/{model}/{t}/{cl}/{sm}.csv\"\n",
    "                all_successful = all_successful_attacks[i]\n",
    "                avg_sim, avg_pp_diff, words_changed_percent = evaluator.evaluate(csv_path, all_successful)\n",
    "                print(f\"{sm}: word_changed_percent={round(words_changed_percent, 2)}, sim={round(avg_sim, 3)}, pp_diff={str(round(avg_pp_diff * 100, 1))}%\")\n",
    "                pbar.update(1)\n",
    "            print(\"=\"*45)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
